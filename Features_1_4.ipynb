{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "641a4a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load datasets\n",
    "orders = pd.read_parquet(\"orders.parquet\")\n",
    "order_products_denormalized = pd.read_csv(\"order_products_denormalized.csv\")\n",
    "tips_public = pd.read_csv(\"tips_public.csv\").drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "# Optimize memory usage by converting to categorical types\n",
    "order_products_denormalized['department'] = order_products_denormalized['department'].astype('category')\n",
    "order_products_denormalized['aisle'] = order_products_denormalized['aisle'].astype('category')\n",
    "\n",
    "# Ensure order_date is datetime\n",
    "orders['order_date'] = pd.to_datetime(orders['order_date'])\n",
    "\n",
    "# Validate data\n",
    "if any(df.empty for df in [orders, order_products_denormalized, tips_public]):\n",
    "    raise ValueError(\"One or more input DataFrames are empty.\")\n",
    "if orders['order_date'].isna().any():\n",
    "    raise ValueError(\"order_date contains missing values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81e7d82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>department</th>\n",
       "      <th>aisle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49302</td>\n",
       "      <td>1</td>\n",
       "      <td>Bulgarian Yogurt</td>\n",
       "      <td>120</td>\n",
       "      <td>16</td>\n",
       "      <td>dairy eggs</td>\n",
       "      <td>yogurt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11109</td>\n",
       "      <td>2</td>\n",
       "      <td>Organic 4% Milk Fat Whole Milk Cottage Cheese</td>\n",
       "      <td>108</td>\n",
       "      <td>16</td>\n",
       "      <td>dairy eggs</td>\n",
       "      <td>other creams cheeses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10246</td>\n",
       "      <td>3</td>\n",
       "      <td>Organic Celery Hearts</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>produce</td>\n",
       "      <td>fresh vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>49683</td>\n",
       "      <td>4</td>\n",
       "      <td>Cucumber Kirby</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>produce</td>\n",
       "      <td>fresh vegetables</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43633</td>\n",
       "      <td>5</td>\n",
       "      <td>Lightly Smoked Sardines in Olive Oil</td>\n",
       "      <td>95</td>\n",
       "      <td>15</td>\n",
       "      <td>canned goods</td>\n",
       "      <td>canned meat seafood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14857348</th>\n",
       "      <td>3421083</td>\n",
       "      <td>39678</td>\n",
       "      <td>6</td>\n",
       "      <td>Free &amp; Clear Natural Dishwasher Detergent</td>\n",
       "      <td>74</td>\n",
       "      <td>17</td>\n",
       "      <td>household</td>\n",
       "      <td>dish detergents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14857349</th>\n",
       "      <td>3421083</td>\n",
       "      <td>11352</td>\n",
       "      <td>7</td>\n",
       "      <td>Organic Mini Sandwich Crackers Peanut Butter</td>\n",
       "      <td>78</td>\n",
       "      <td>19</td>\n",
       "      <td>snacks</td>\n",
       "      <td>crackers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14857350</th>\n",
       "      <td>3421083</td>\n",
       "      <td>4600</td>\n",
       "      <td>8</td>\n",
       "      <td>All Natural French Toast Sticks</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>frozen</td>\n",
       "      <td>frozen breakfast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14857351</th>\n",
       "      <td>3421083</td>\n",
       "      <td>24852</td>\n",
       "      <td>9</td>\n",
       "      <td>Banana</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>produce</td>\n",
       "      <td>fresh fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14857352</th>\n",
       "      <td>3421083</td>\n",
       "      <td>5020</td>\n",
       "      <td>10</td>\n",
       "      <td>Organic  Sweet &amp; Salty Peanut Pretzel Granola ...</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>snacks</td>\n",
       "      <td>energy granola bars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14857353 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          order_id  product_id  add_to_cart_order  \\\n",
       "0                1       49302                  1   \n",
       "1                1       11109                  2   \n",
       "2                1       10246                  3   \n",
       "3                1       49683                  4   \n",
       "4                1       43633                  5   \n",
       "...            ...         ...                ...   \n",
       "14857348   3421083       39678                  6   \n",
       "14857349   3421083       11352                  7   \n",
       "14857350   3421083        4600                  8   \n",
       "14857351   3421083       24852                  9   \n",
       "14857352   3421083        5020                 10   \n",
       "\n",
       "                                               product_name  aisle_id  \\\n",
       "0                                          Bulgarian Yogurt       120   \n",
       "1             Organic 4% Milk Fat Whole Milk Cottage Cheese       108   \n",
       "2                                     Organic Celery Hearts        83   \n",
       "3                                            Cucumber Kirby        83   \n",
       "4                      Lightly Smoked Sardines in Olive Oil        95   \n",
       "...                                                     ...       ...   \n",
       "14857348          Free & Clear Natural Dishwasher Detergent        74   \n",
       "14857349       Organic Mini Sandwich Crackers Peanut Butter        78   \n",
       "14857350                    All Natural French Toast Sticks        52   \n",
       "14857351                                             Banana        24   \n",
       "14857352  Organic  Sweet & Salty Peanut Pretzel Granola ...         3   \n",
       "\n",
       "          department_id    department                 aisle  \n",
       "0                    16    dairy eggs                yogurt  \n",
       "1                    16    dairy eggs  other creams cheeses  \n",
       "2                     4       produce      fresh vegetables  \n",
       "3                     4       produce      fresh vegetables  \n",
       "4                    15  canned goods   canned meat seafood  \n",
       "...                 ...           ...                   ...  \n",
       "14857348             17     household       dish detergents  \n",
       "14857349             19        snacks              crackers  \n",
       "14857350              1        frozen      frozen breakfast  \n",
       "14857351              4       produce          fresh fruits  \n",
       "14857352             19        snacks   energy granola bars  \n",
       "\n",
       "[14857353 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_products_denormalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_overview",
   "metadata": {},
   "source": [
    "## Feature Overview\n",
    "\n",
    "The following table lists all features engineered in this notebook, including their level, output columns, data types, and descriptions.\n",
    "\n",
    "| **Feature Name** | **Level** | **Output Columns** | **Data Type** | **Description** |\n",
    "|------------------|-----------|--------------------|---------------|-----------------|\n",
    "| `alcohol_purchases` | User | `[user_id, alcohol_purchases]` | Integer | Counts the total number of alcohol products purchased by each user across all orders. |\n",
    "| `total_products_bought` | User | `[user_id, total_products_bought]` | Integer | Counts the total number of products purchased by each user across all orders. |\n",
    "| `unique_products_bought` | User | `[user_id, unique_products_bought]` | Integer | Counts the number of unique products purchased by each user. |\n",
    "| `unique_to_total_product_ratio` | User | `[user_id, unique_to_total_product_ratio]` | Float | Calculates the ratio of unique products to total products purchased by each user (unique_products_bought / total_products_bought). |\n",
    "| `most_frequent_hour` | User | `[user_id, most_frequent_hour]` | Integer (0â€“23) | Identifies the hour of the day when the user places the most orders, defaulting to 12 (noon) if missing. |\n",
    "| `most_frequent_dow` | User | `[user_id, most_frequent_dow]` | Integer (0â€“6) | Identifies the day of the week (0=Monday, 6=Sunday) when the user places the most orders, defaulting to 0 (Monday). |\n",
    "| `avg_time_between_orders_hours` | User | `[user_id, avg_time_between_orders_hours]` | Float | Calculates the average time (in hours) between consecutive orders for each user, using the dataset median for users with one order. |\n",
    "| `purchase_hour_sin`, `purchase_hour_cos` | User | `[user_id, purchase_hour_sin, purchase_hour_cos]` | Float (-1 to 1) | Applies sine-cosine transformation to the most frequent purchase hour to capture its cyclical nature. |\n",
    "| `purchase_season_sin`, `purchase_season_cos` | User | `[user_id, purchase_season_sin, purchase_season_cos]` | Float (-1 to 1) | Applies sine-cosine transformation to the most frequent purchase month to capture seasonal cyclicality, defaulting to January. |\n",
    "| `contains_alcohol` | Order | `[order_id, contains_alcohol]` | Integer (0 or 1) | Flags whether an order contains any alcohol products (1 if yes, 0 if no). |\n",
    "| `item_count` | Order | `[order_id, item_count]` | Integer | Counts the total number of items (products) in each order. |\n",
    "| `unique_departments_count` | Order | `[order_id, unique_departments_count]` | Integer | Counts the number of unique departments in each order. |\n",
    "| `unique_aisles_count` | Order | `[order_id, unique_aisles_count]` | Integer | Counts the number of unique aisles in each order. |\n",
    "| `unique_departments_ratio` | Order | `[order_id, unique_departments_ratio]` | Float | Calculates the ratio of unique departments to total items in each order (unique_departments_count / item_count). |\n",
    "| `unique_aisles_ratio` | Order | `[order_id, unique_aisles_ratio]` | Float | Calculates the ratio of unique aisles to total items in each order (unique_aisles_count / item_count). |\n",
    "| `avg_tip_rate_department` | Order | `[order_id, avg_tip_rate_department]` | Float (0 to 1) | Computes the average tip rate for the departments in an order based on prior orders, defaulting to 0.5 for no history. |\n",
    "| `avg_tip_rate_aisle` | Order | `[order_id, avg_tip_rate_aisle]` | Float (0 to 1) | Computes the average tip rate for the aisles in an order based on prior orders, defaulting to 0.5 for no history. |\n",
    "| `order_hour` | Order | `[order_id, order_hour]` | Integer (0â€“23) | Extracts the hour of the day when the order was placed. |\n",
    "| `order_dow` | Order | `[order_id, order_dow]` | Integer (0â€“6) | Extracts the day of the week (0=Monday, 6=Sunday) when the order was placed. |\n",
    "| `is_weekend` | Order | `[order_id, is_weekend]` | Integer (0 or 1) | Flags whether the order was placed on a weekend (Saturday or Sunday). |\n",
    "| `order_hour_sin`, `order_hour_cos` | Order | `[order_id, order_hour_sin, order_hour_cos]` | Float (-1 to 1) | Applies sine-cosine transformation to the orderâ€™s hour to capture its cyclical nature. |\n",
    "| `order_season_sin`, `order_season_cos` | Order | `[order_id, order_season_sin, order_season_cos]` | Float (-1 to 1) | Applies sine-cosine transformation to the orderâ€™s month to capture seasonal cyclicality. |\n",
    "| `time_since_last_order_hours` | Order | `[order_id, time_since_last_order_hours]` | Float | Calculates the time (in hours) since the userâ€™s previous order, using the dataset median for first orders. |\n",
    "| `times_bought` | User-Product | `[user_id, product_id, times_bought]` | Integer | Counts how many times each user has purchased each product. |\n",
    "| `tip_probability` | User-Product | `[user_id, product_id, tip_probability]` | Float (0 to 1) | Calculates the average tip probability for each user-product pair based on prior orders, defaulting to 0.5 for no history. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e01af71",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "Common operations used across feature engineering functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "helper_functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_with_orders(df, columns=['order_id', 'user_id']):\n",
    "    \"\"\"Merge a DataFrame with orders to include user_id and/or other columns.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing order_id.\n",
    "        columns (list): Columns from orders to include.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Merged DataFrame.\n",
    "    \"\"\"\n",
    "    return df.merge(orders[columns], on='order_id', how='left')\n",
    "\n",
    "def validate_dataframe(df, required_columns):\n",
    "    \"\"\"Check if DataFrame has required columns and is not empty.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to validate.\n",
    "        required_columns (list): List of required column names.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If validation fails.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        raise ValueError(\"DataFrame is empty.\")\n",
    "    missing_cols = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "\n",
    "def cyclic_transform(value, max_value):\n",
    "    \"\"\"Apply sine-cosine transformation to a cyclical value.\n",
    "    \n",
    "    Args:\n",
    "        value (pd.Series): Values to transform (e.g., hour or month).\n",
    "        max_value (float): Maximum value of the cycle (e.g., 24 for hours, 12 for months).\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (sin_values, cos_values) as pd.Series.\n",
    "    \"\"\"\n",
    "    radians = 2 * np.pi * value / max_value\n",
    "    return np.sin(radians), np.cos(radians)\n",
    "\n",
    "def compute_median_time_diff():\n",
    "    \"\"\"Compute median time difference between consecutive orders across all users.\n",
    "    \n",
    "    Returns:\n",
    "        float: Median time difference in hours.\n",
    "    \"\"\"\n",
    "    sorted_orders = orders[['user_id', 'order_date']].sort_values(['user_id', 'order_date'])\n",
    "    time_diffs = sorted_orders.groupby('user_id')['order_date'].diff().dt.total_seconds() / 3600\n",
    "    return time_diffs.median() if not time_diffs.empty else 24.0  # Default to 24 hours if empty\n",
    "\n",
    "def downcast_dtypes(df):\n",
    "    \"\"\"Downcast numeric columns to reduce memory usage.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to downcast.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Downcasted DataFrame.\n",
    "    \"\"\"\n",
    "    for col in df.select_dtypes(include=['int64']).columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "    for col in df.select_dtypes(include=['float64']).columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "user_features",
   "metadata": {},
   "source": [
    "## Feature Engineering: User-Level Features\n",
    "\n",
    "Each feature returns a DataFrame with columns: user_id, feature_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "user_features",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature_alcohol_count():\n",
    "    \"\"\"Count how many alcohol products each user has purchased.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [user_id, alcohol_purchases].\n",
    "    \"\"\"\n",
    "    alcohol_df = order_products_denormalized[order_products_denormalized['department'] == 'alcohol']\n",
    "    if alcohol_df.empty:\n",
    "        return pd.DataFrame({'user_id': orders['user_id'].unique(), 'alcohol_purchases': 0})\n",
    "    \n",
    "    alcohol_with_users = merge_with_orders(alcohol_df)\n",
    "    alcohol_counts = alcohol_with_users.groupby('user_id').size().reset_index(name='alcohol_purchases')\n",
    "    \n",
    "    all_users = pd.DataFrame({'user_id': orders['user_id'].unique()})\n",
    "    result = all_users.merge(alcohol_counts, on='user_id', how='left').fillna({'alcohol_purchases': 0})\n",
    "    result = downcast_dtypes(result)\n",
    "    \n",
    "    validate_dataframe(result, ['user_id', 'alcohol_purchases'])\n",
    "    return result\n",
    "\n",
    "def total_products_per_user():\n",
    "    \"\"\"Count total products purchased by each user.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [user_id, total_products_bought].\n",
    "    \"\"\"\n",
    "    merged = merge_with_orders(order_products_denormalized)\n",
    "    total_products = merged.groupby('user_id')['product_id'].count().reset_index(name='total_products_bought')\n",
    "    total_products = downcast_dtypes(total_products)\n",
    "    \n",
    "    validate_dataframe(total_products, ['user_id', 'total_products_bought'])\n",
    "    return total_products\n",
    "\n",
    "def total_unique_products_per_user():\n",
    "    \"\"\"Count unique products purchased by each user.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [user_id, unique_products_bought].\n",
    "    \"\"\"\n",
    "    merged = merge_with_orders(order_products_denormalized)\n",
    "    unique_products = merged.groupby('user_id')['product_id'].nunique().reset_index(name='unique_products_bought')\n",
    "    unique_products = downcast_dtypes(unique_products)\n",
    "    \n",
    "    validate_dataframe(unique_products, ['user_id', 'unique_products_bought'])\n",
    "    return unique_products\n",
    "\n",
    "def unique_to_total_product_ratio_per_user():\n",
    "    \"\"\"Calculate ratio of unique to total products purchased by each user.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [user_id, unique_to_total_product_ratio].\n",
    "    \"\"\"\n",
    "    total = total_products_per_user()\n",
    "    unique = total_unique_products_per_user()\n",
    "    merged = total.merge(unique, on='user_id')\n",
    "    merged['unique_to_total_product_ratio'] = merged['unique_products_bought'] / merged['total_products_bought']\n",
    "    merged = downcast_dtypes(merged)\n",
    "    \n",
    "    validate_dataframe(merged, ['user_id', 'unique_to_total_product_ratio'])\n",
    "    return merged[['user_id', 'unique_to_total_product_ratio']]\n",
    "\n",
    "def most_frequent_purchase_hour():\n",
    "    \"\"\"Identify the most frequent hour of day for each user's orders.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [user_id, most_frequent_hour].\n",
    "    \"\"\"\n",
    "    orders_with_hour = orders[['user_id', 'order_date']].copy()\n",
    "    orders_with_hour['hour'] = orders_with_hour['order_date'].dt.hour\n",
    "    \n",
    "    hour_counts = orders_with_hour.groupby(['user_id', 'hour']).size().reset_index(name='count')\n",
    "    idx = hour_counts.groupby('user_id')['count'].idxmax()\n",
    "    result = hour_counts.loc[idx, ['user_id', 'hour']].rename(columns={'hour': 'most_frequent_hour'})\n",
    "    \n",
    "    all_users = pd.DataFrame({'user_id': orders['user_id'].unique()})\n",
    "    result = all_users.merge(result, on='user_id', how='left').fillna({'most_frequent_hour': 12})  # Default to noon\n",
    "    result = downcast_dtypes(result)\n",
    "    \n",
    "    validate_dataframe(result, ['user_id', 'most_frequent_hour'])\n",
    "    return result\n",
    "\n",
    "def most_frequent_purchase_dow():\n",
    "    \"\"\"Identify the most frequent day of week for each user's orders (0=Monday, 6=Sunday).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [user_id, most_frequent_dow].\n",
    "    \"\"\"\n",
    "    orders_with_dow = orders[['user_id', 'order_date']].copy()\n",
    "    orders_with_dow['dow'] = orders_with_dow['order_date'].dt.dayofweek\n",
    "    \n",
    "    dow_counts = orders_with_dow.groupby(['user_id', 'dow']).size().reset_index(name='count')\n",
    "    idx = dow_counts.groupby('user_id')['count'].idxmax()\n",
    "    result = dow_counts.loc[idx, ['user_id', 'dow']].rename(columns={'dow': 'most_frequent_dow'})\n",
    "    \n",
    "    all_users = pd.DataFrame({'user_id': orders['user_id'].unique()})\n",
    "    result = all_users.merge(result, on='user_id', how='left').fillna({'most_frequent_dow': 0})  # Default to Monday\n",
    "    result = downcast_dtypes(result)\n",
    "    \n",
    "    validate_dataframe(result, ['user_id', 'most_frequent_dow'])\n",
    "    return result\n",
    "\n",
    "def avg_time_between_orders():\n",
    "    \"\"\"Calculate average time between consecutive orders for each user in hours.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [user_id, avg_time_between_orders_hours].\n",
    "    \"\"\"\n",
    "    sorted_orders = orders[['user_id', 'order_date']].sort_values(['user_id', 'order_date'])\n",
    "    time_diffs = sorted_orders.groupby('user_id')['order_date'].diff().dt.total_seconds() / 3600\n",
    "    \n",
    "    avg_diffs = time_diffs.groupby(sorted_orders['user_id']).mean().reset_index(name='avg_time_between_orders_hours')\n",
    "    all_users = pd.DataFrame({'user_id': orders['user_id'].unique()})\n",
    "    result = all_users.merge(avg_diffs, on='user_id', how='left')\n",
    "    result['avg_time_between_orders_hours'] = result['avg_time_between_orders_hours'].fillna(compute_median_time_diff())\n",
    "    result = downcast_dtypes(result)\n",
    "    \n",
    "    validate_dataframe(result, ['user_id', 'avg_time_between_orders_hours'])\n",
    "    return result\n",
    "\n",
    "def purchase_hour_cyclic():\n",
    "    \"\"\"Apply sine-cosine transformation to the most frequent purchase hour.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [user_id, purchase_hour_sin, purchase_hour_cos].\n",
    "    \"\"\"\n",
    "    hours = most_frequent_purchase_hour()\n",
    "    sin_vals, cos_vals = cyclic_transform(hours['most_frequent_hour'], 24)\n",
    "    \n",
    "    result = hours[['user_id']].copy()\n",
    "    result['purchase_hour_sin'] = sin_vals\n",
    "    result['purchase_hour_cos'] = cos_vals\n",
    "    result = downcast_dtypes(result)\n",
    "    \n",
    "    validate_dataframe(result, ['user_id', 'purchase_hour_sin', 'purchase_hour_cos'])\n",
    "    return result\n",
    "\n",
    "def purchase_season_cyclic():\n",
    "    \"\"\"Apply sine-cosine transformation to the most frequent purchase month.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [user_id, purchase_season_sin, purchase_season_cos].\n",
    "    \"\"\"\n",
    "    orders_with_month = orders[['user_id', 'order_date']].copy()\n",
    "    orders_with_month['month'] = orders_with_month['order_date'].dt.month\n",
    "    \n",
    "    month_counts = orders_with_month.groupby(['user_id', 'month']).size().reset_index(name='count')\n",
    "    idx = month_counts.groupby('user_id')['count'].idxmax()\n",
    "    most_frequent_month = month_counts.loc[idx, ['user_id', 'month']].rename(columns={'month': 'most_frequent_month'})\n",
    "    \n",
    "    all_users = pd.DataFrame({'user_id': orders['user_id'].unique()})\n",
    "    most_frequent_month = all_users.merge(most_frequent_month, on='user_id', how='left').fillna({'most_frequent_month': 1})  # Default to January\n",
    "    \n",
    "    sin_vals, cos_vals = cyclic_transform(most_frequent_month['most_frequent_month'], 12)\n",
    "    result = most_frequent_month[['user_id']].copy()\n",
    "    result['purchase_season_sin'] = sin_vals\n",
    "    result['purchase_season_cos'] = cos_vals\n",
    "    result = downcast_dtypes(result)\n",
    "    \n",
    "    validate_dataframe(result, ['user_id', 'purchase_season_sin', 'purchase_season_cos'])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "order_features",
   "metadata": {},
   "source": [
    "## Feature Engineering: Order-Level Features\n",
    "\n",
    "Each feature returns a DataFrame with columns: order_id, feature_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "order_features",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature_order_contains_alcohol():\n",
    "    \"\"\"Flag orders containing alcohol products.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [order_id, contains_alcohol].\n",
    "    \"\"\"\n",
    "    alcohol_orders = order_products_denormalized[order_products_denormalized['department'] == 'alcohol'][['order_id']].drop_duplicates()\n",
    "    alcohol_orders['contains_alcohol'] = 1\n",
    "    \n",
    "    all_orders = pd.DataFrame({'order_id': orders['order_id'].unique()})\n",
    "    result = all_orders.merge(alcohol_orders, on='order_id', how='left').fillna({'contains_alcohol': 0})\n",
    "    result = downcast_dtypes(result)\n",
    "    \n",
    "    validate_dataframe(result, ['order_id', 'contains_alcohol'])\n",
    "    return result\n",
    "\n",
    "def add_feature_order_item_count():\n",
    "    \"\"\"Count total items in each order.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [order_id, item_count].\n",
    "    \"\"\"\n",
    "    item_counts = order_products_denormalized.groupby('order_id')['product_id'].count().reset_index(name='item_count')\n",
    "    item_counts = downcast_dtypes(item_counts)\n",
    "    \n",
    "    validate_dataframe(item_counts, ['order_id', 'item_count'])\n",
    "    return item_counts\n",
    "\n",
    "def add_feature_order_unique_departments_count():\n",
    "    \"\"\"Count unique departments in each order.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [order_id, unique_departments_count].\n",
    "    \"\"\"\n",
    "    dept_counts = order_products_denormalized.groupby('order_id')['department'].nunique().reset_index(name='unique_departments_count')\n",
    "    dept_counts = downcast_dtypes(dept_counts)\n",
    "    \n",
    "    validate_dataframe(dept_counts, ['order_id', 'unique_departments_count'])\n",
    "    return dept_counts\n",
    "\n",
    "def add_feature_order_unique_aisles_count():\n",
    "    \"\"\"Count unique aisles in each order.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [order_id, unique_aisles_count].\n",
    "    \"\"\"\n",
    "    aisle_counts = order_products_denormalized.groupby('order_id')['aisle'].nunique().reset_index(name='unique_aisles_count')\n",
    "    aisle_counts = downcast_dtypes(aisle_counts)\n",
    "    \n",
    "    validate_dataframe(aisle_counts, ['order_id', 'unique_aisles_count'])\n",
    "    return aisle_counts\n",
    "\n",
    "def add_feature_order_unique_departments_ratio():\n",
    "    \"\"\"Calculate ratio of unique departments to total items in each order.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [order_id, unique_departments_ratio].\n",
    "    \"\"\"\n",
    "    total_items = add_feature_order_item_count()\n",
    "    unique_depts = add_feature_order_unique_departments_count()\n",
    "    merged = total_items.merge(unique_depts, on='order_id')\n",
    "    merged['unique_departments_ratio'] = merged['unique_departments_count'] / merged['item_count']\n",
    "    merged = downcast_dtypes(merged)\n",
    "    \n",
    "    validate_dataframe(merged, ['order_id', 'unique_departments_ratio'])\n",
    "    return merged[['order_id', 'unique_departments_ratio']]\n",
    "\n",
    "def add_feature_order_unique_aisles_ratio():\n",
    "    \"\"\"Calculate ratio of unique aisles to total items in each order.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [order_id, unique_aisles_ratio].\n",
    "    \"\"\"\n",
    "    total_items = add_feature_order_item_count()\n",
    "    unique_aisles = add_feature_order_unique_aisles_count()\n",
    "    merged = total_items.merge(unique_aisles, on='order_id')\n",
    "    merged['unique_aisles_ratio'] = merged['unique_aisles_count'] / merged['item_count']\n",
    "    merged = downcast_dtypes(merged)\n",
    "    \n",
    "    validate_dataframe(merged, ['order_id', 'unique_aisles_ratio'])\n",
    "    return merged[['order_id', 'unique_aisles_ratio']]\n",
    "\n",
    "def add_feature_avg_tip_rate_department(default_tip_rate=0.5):\n",
    "    \"\"\"Calculate the average tip rate for each department up to the order date, aggregated per order.\n",
    "    \n",
    "    Args:\n",
    "        default_tip_rate (float): Default tip rate for departments with no prior orders.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [order_id, avg_tip_rate_department].\n",
    "    \"\"\"\n",
    "    merged = order_products_denormalized.merge(\n",
    "        orders[['order_id', 'order_date']], on='order_id'\n",
    "    ).merge(\n",
    "        tips_public[['order_id', 'tip']], on='order_id', how='left'\n",
    "    )\n",
    "    \n",
    "    merged['tip'] = merged['tip'].fillna(0).astype('float32')\n",
    "    merged = merged.sort_values(by=['department', 'order_date'])\n",
    "    \n",
    "    merged['order_count'] = merged.groupby('department').cumcount().astype('int32')\n",
    "    merged['tip_cumsum_before'] = merged.groupby('department')['tip'].cumsum() - merged['tip']\n",
    "    merged['avg_tip_rate_before'] = merged['tip_cumsum_before'] / merged['order_count']\n",
    "    merged.loc[merged['order_count'] == 0, 'avg_tip_rate_before'] = pd.NA\n",
    "    \n",
    "    order_tip_rate = merged.groupby('order_id')['avg_tip_rate_before'].mean().reset_index(name='avg_tip_rate_department')\n",
    "    order_tip_rate['avg_tip_rate_department'] = order_tip_rate['avg_tip_rate_department'].fillna(default_tip_rate).astype('float32')\n",
    "    order_tip_rate = downcast_dtypes(order_tip_rate)\n",
    "    \n",
    "    validate_dataframe(order_tip_rate, ['order_id', 'avg_tip_rate_department'])\n",
    "    return order_tip_rate\n",
    "\n",
    "def add_feature_avg_tip_rate_aisle(default_tip_rate=0.5):\n",
    "    \"\"\"Calculate the average tip rate for each aisle up to the order date, aggregated per order.\n",
    "    \n",
    "    Args:\n",
    "        default_tip_rate (float): Default tip rate for aisles with no prior orders.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [order_id, avg_tip_rate_aisle].\n",
    "    \"\"\"\n",
    "    merged = order_products_denormalized.merge(\n",
    "        orders[['order_id', 'order_date']], on='order_id'\n",
    "    ).merge(\n",
    "        tips_public[['order_id', 'tip']], on='order_id', how='left'\n",
    "    )\n",
    "    \n",
    "    merged['tip'] = merged['tip'].fillna(0).astype('float32')\n",
    "    merged = merged.sort_values(by=['aisle', 'order_date'])\n",
    "    \n",
    "    merged['order_count'] = merged.groupby('aisle').cumcount().astype('int32')\n",
    "    merged['tip_cumsum_before'] = merged.groupby('aisle')['tip'].cumsum() - merged['tip']\n",
    "    merged['avg_tip_rate_before'] = merged['tip_cumsum_before'] / merged['order_count']\n",
    "    merged.loc[merged['order_count'] == 0, 'avg_tip_rate_before'] = pd.NA\n",
    "    \n",
    "    order_tip_rate = merged.groupby('order_id')['avg_tip_rate_before'].mean().reset_index(name='avg_tip_rate_aisle')\n",
    "    order_tip_rate['avg_tip_rate_aisle'] = order_tip_rate['avg_tip_rate_aisle'].fillna(default_tip_rate).astype('float32')\n",
    "    order_tip_rate = downcast_dtypes(order_tip_rate)\n",
    "    \n",
    "    validate_dataframe(order_tip_rate, ['order_id', 'avg_tip_rate_aisle'])\n",
    "    return order_tip_rate\n",
    "\n",
    "def order_hour():\n",
    "    \"\"\"Extract the hour of the day for each order.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [order_id, order_hour].\n",
    "    \"\"\"\n",
    "    result = orders[['order_id', 'order_date']].copy()\n",
    "    result['order_hour'] = result['order_date'].dt.hour\n",
    "    result = downcast_dtypes(result)\n",
    "    \n",
    "    validate_dataframe(result, ['order_id', 'order_hour'])\n",
    "    return result[['order_id', 'order_hour']]\n",
    "\n",
    "def order_dow():\n",
    "    \"\"\"Extract the day of week for each order (0=Monday, 6=Sunday).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [order_id, 'order_dow'].\n",
    "    \"\"\"\n",
    "    result = orders[['order_id', 'order_date']].copy()\n",
    "    result['order_dow'] = result['order_date'].dt.dayofweek\n",
    "    result = downcast_dtypes(result)\n",
    "    \n",
    "    validate_dataframe(result, ['order_id', 'order_dow'])\n",
    "    return result[['order_id', 'order_dow']]\n",
    "\n",
    "def is_weekend_order():\n",
    "    \"\"\"Flag orders placed on weekends (Saturday or Sunday).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [order_id, is_weekend].\n",
    "    \"\"\"\n",
    "    dow = order_dow()\n",
    "    result = dow[['order_id']].copy()\n",
    "    result['is_weekend'] = dow['order_dow'].isin([5, 6]).astype('int8')\n",
    "    result = downcast_dtypes(result)\n",
    "    \n",
    "    validate_dataframe(result, ['order_id', 'is_weekend'])\n",
    "    return result\n",
    "\n",
    "def order_hour_cyclic():\n",
    "    \"\"\"Apply sine-cosine transformation to the order hour.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [order_id, order_hour_sin, order_hour_cos].\n",
    "    \"\"\"\n",
    "    hours = order_hour()\n",
    "    sin_vals, cos_vals = cyclic_transform(hours['order_hour'], 24)\n",
    "    \n",
    "    result = hours[['order_id']].copy()\n",
    "    result['order_hour_sin'] = sin_vals\n",
    "    result['order_hour_cos'] = cos_vals\n",
    "    result = downcast_dtypes(result)\n",
    "    \n",
    "    validate_dataframe(result, ['order_id', 'order_hour_sin', 'order_hour_cos'])\n",
    "    return result\n",
    "\n",
    "def order_season_cyclic():\n",
    "    \"\"\"Apply sine-cosine transformation to the order month.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [order_id, order_season_sin, order_season_cos].\n",
    "    \"\"\"\n",
    "    result = orders[['order_id', 'order_date']].copy()\n",
    "    result['month'] = result['order_date'].dt.month\n",
    "    \n",
    "    sin_vals, cos_vals = cyclic_transform(result['month'], 12)\n",
    "    result['order_season_sin'] = sin_vals\n",
    "    result['order_season_cos'] = cos_vals\n",
    "    result = downcast_dtypes(result)\n",
    "    \n",
    "    validate_dataframe(result, ['order_id', 'order_season_sin', 'order_season_cos'])\n",
    "    return result[['order_id', 'order_season_sin', 'order_season_cos']]\n",
    "\n",
    "def time_since_last_order():\n",
    "    \"\"\"Calculate time since the user's last order in hours.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [order_id, time_since_last_order_hours].\n",
    "    \"\"\"\n",
    "    sorted_orders = orders[['order_id', 'user_id', 'order_date']].sort_values(['user_id', 'order_date'])\n",
    "    time_diffs = sorted_orders.groupby('user_id')['order_date'].diff().shift(-1).dt.total_seconds() / 3600\n",
    "    time_diffs = time_diffs.reindex(sorted_orders.index).shift(1)  # Shift back to align with current order\n",
    "    \n",
    "    result = sorted_orders[['order_id']].copy()\n",
    "    result['time_since_last_order_hours'] = time_diffs.fillna(compute_median_time_diff())\n",
    "    result = downcast_dtypes(result)\n",
    "    \n",
    "    validate_dataframe(result, ['order_id', 'time_since_last_order_hours'])\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "user_product_features",
   "metadata": {},
   "source": [
    "## Feature Engineering: User-Product-Level Features\n",
    "\n",
    "Each feature returns a DataFrame with columns: user_id, product_id, feature_name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "user_product_features",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_products_per_user():\n",
    "    \"\"\"Count how many times each user purchased each product.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Columns [user_id, product_id, times_bought].\n",
    "    \"\"\"\n",
    "    merged = merge_with_orders(order_products_denormalized)\n",
    "    counts = merged.groupby(['user_id', 'product_id']).size().reset_index(name='times_bought')\n",
    "    counts = downcast_dtypes(counts)\n",
    "    \n",
    "    validate_dataframe(counts, ['user_id', 'product_id', 'times_bought'])\n",
    "    return counts\n",
    "\n",
    "def create_user_product_tip_probability(default_tip_rate=0.500111):\n",
    "    \"\"\"Berechnet die durchschnittliche Trinkgeldwahrscheinlichkeit pro (user_id, product_id)-Paar\n",
    "    und verknÃ¼pft sie mit order_products_denormalized, ohne die Zeilenanzahl zu Ã¤ndern.\n",
    "    \n",
    "    Args:\n",
    "        default_tip_rate (float): Standard-Trinkgeldwahrscheinlichkeit fÃ¼r Paare ohne Historie.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame mit order_id, user_id, product_id und tip_probability.\n",
    "    \"\"\"\n",
    "    # Schritt 1: Validierung der Eingabedaten\n",
    "    if 'user_id' not in orders.columns:\n",
    "        raise ValueError(\"Spalte 'user_id' fehlt in orders DataFrame\")\n",
    "    if 'order_id' not in order_products_denormalized.columns:\n",
    "        raise ValueError(\"Spalte 'order_id' fehlt in order_products_denormalized DataFrame\")\n",
    "    \n",
    "    # Schritt 2: Merge der DataFrames, um user_id hinzuzufÃ¼gen\n",
    "    merged = order_products_denormalized.merge(\n",
    "        orders[['order_id', 'user_id', 'order_date']], \n",
    "        on='order_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Validierung nach erstem Merge\n",
    "    if 'user_id' not in merged.columns:\n",
    "        raise ValueError(\"user_id fehlt nach Merge mit orders. ÃœberprÃ¼fe order_id Ãœbereinstimmungen.\")\n",
    "    if merged['user_id'].isna().any():\n",
    "        print(f\"Warnung: {merged['user_id'].isna().sum()} Zeilen mit fehlendem user_id nach Merge mit orders\")\n",
    "        merged = merged.dropna(subset=['user_id'])  # Entferne Zeilen mit fehlendem user_id\n",
    "    \n",
    "    merged = merged.merge(\n",
    "        tips_public[['order_id', 'tip']], \n",
    "        on='order_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Schritt 3: Optimierung und Berechnung\n",
    "    merged['tip'] = merged['tip'].fillna(0).astype('float32')\n",
    "    merged = merged.sort_values(by=['user_id', 'product_id', 'order_date'])\n",
    "    \n",
    "    merged['times_bought_before'] = merged.groupby(['user_id', 'product_id']).cumcount().astype('int32')\n",
    "    merged['tip_cumsum_before'] = merged.groupby(['user_id', 'product_id'])['tip'].cumsum() - merged['tip']\n",
    "    merged['avg_tip_rate_before'] = merged['tip_cumsum_before'] / merged['times_bought_before']\n",
    "    merged.loc[merged['times_bought_before'] == 0, 'avg_tip_rate_before'] = pd.NA\n",
    "    \n",
    "    # Schritt 4: Aggregation zu user-product Ebene\n",
    "    user_product_tip = merged.groupby(['user_id', 'product_id'])['avg_tip_rate_before'].mean().reset_index(\n",
    "        name='tip_probability'\n",
    "    )\n",
    "    user_product_tip['tip_probability'] = user_product_tip['tip_probability'].fillna(default_tip_rate).astype('float32')\n",
    "    user_product_tip = downcast_dtypes(user_product_tip, exclude_columns=['user_id', 'product_id'])\n",
    "    \n",
    "    # Schritt 5: VerknÃ¼pfung mit order_products_denormalized, inklusive user_id\n",
    "    result = order_products_denormalized.merge(\n",
    "        orders[['order_id', 'user_id']], \n",
    "        on='order_id', \n",
    "        how='left'\n",
    "    ).merge(\n",
    "        user_product_tip[['user_id', 'product_id', 'tip_probability']],\n",
    "        on=['user_id', 'product_id'],\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # FÃ¼lle fehlende Werte\n",
    "    result['tip_probability'] = result['tip_probability'].fillna(default_tip_rate).astype('float32')\n",
    "    result = downcast_dtypes(result, exclude_columns=['order_id', 'user_id', 'product_id'])\n",
    "    \n",
    "    # Schritt 6: Validierung\n",
    "    if len(result) != len(order_products_denormalized):\n",
    "        raise ValueError(f\"Zeilenanzahl stimmt nicht: {len(result)} statt {len(order_products_denormalized)}\")\n",
    "    expected_columns = list(order_products_denormalized.columns) + ['user_id', 'tip_probability']\n",
    "    validate_dataframe(result, expected_columns)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_consolidation",
   "metadata": {},
   "source": [
    "## Feature Consolidation\n",
    "\n",
    "Combine all features into a single DataFrame for a comprehensive view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feature_consolidation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_27416\\866613141.py:101: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  merged['order_count'] = merged.groupby('department').cumcount().astype('int32')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_27416\\866613141.py:102: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  merged['tip_cumsum_before'] = merged.groupby('department')['tip'].cumsum() - merged['tip']\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_27416\\866613141.py:131: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  merged['order_count'] = merged.groupby('aisle').cumcount().astype('int32')\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_27416\\866613141.py:132: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  merged['tip_cumsum_before'] = merged.groupby('aisle')['tip'].cumsum() - merged['tip']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging feature with columns ['order_id', 'contains_alcohol'], order_id dtype: int64\n",
      "Merging feature with columns ['order_id', 'item_count'], order_id dtype: int64\n",
      "Merging feature with columns ['order_id', 'unique_departments_count'], order_id dtype: int64\n",
      "Merging feature with columns ['order_id', 'unique_aisles_count'], order_id dtype: int64\n",
      "Merging feature with columns ['order_id', 'unique_departments_ratio'], order_id dtype: int64\n",
      "Merging feature with columns ['order_id', 'unique_aisles_ratio'], order_id dtype: int64\n",
      "Merging feature with columns ['order_id', 'avg_tip_rate_department'], order_id dtype: int64\n",
      "Merging feature with columns ['order_id', 'avg_tip_rate_aisle'], order_id dtype: int64\n",
      "Merging feature with columns ['order_id', 'order_hour'], order_id dtype: int64\n",
      "Merging feature with columns ['order_id', 'order_dow'], order_id dtype: int64\n",
      "Merging feature with columns ['order_id', 'is_weekend'], order_id dtype: int64\n",
      "Merging feature with columns ['order_id', 'order_hour_sin', 'order_hour_cos'], order_id dtype: int64\n",
      "Merging feature with columns ['order_id', 'order_season_sin', 'order_season_cos'], order_id dtype: int64\n",
      "Merging feature with columns ['order_id', 'time_since_last_order_hours'], order_id dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>contains_alcohol</th>\n",
       "      <th>item_count</th>\n",
       "      <th>unique_departments_count</th>\n",
       "      <th>unique_aisles_count</th>\n",
       "      <th>unique_departments_ratio</th>\n",
       "      <th>unique_aisles_ratio</th>\n",
       "      <th>avg_tip_rate_department</th>\n",
       "      <th>avg_tip_rate_aisle</th>\n",
       "      <th>...</th>\n",
       "      <th>most_frequent_hour</th>\n",
       "      <th>most_frequent_dow</th>\n",
       "      <th>avg_time_between_orders_hours</th>\n",
       "      <th>purchase_hour_sin</th>\n",
       "      <th>purchase_hour_cos</th>\n",
       "      <th>purchase_season_sin</th>\n",
       "      <th>purchase_season_cos</th>\n",
       "      <th>total_times_bought</th>\n",
       "      <th>tip_probability</th>\n",
       "      <th>tip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1374495</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.516237</td>\n",
       "      <td>0.523879</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>288.102417</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>88</td>\n",
       "      <td>0.849794</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>444309</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502990</td>\n",
       "      <td>0.499790</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>288.102417</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>88</td>\n",
       "      <td>0.714135</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3002854</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.510314</td>\n",
       "      <td>0.507816</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>288.102417</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>88</td>\n",
       "      <td>0.791323</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2037211</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.442459</td>\n",
       "      <td>0.457083</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>288.102417</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>88</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2710558</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.518061</td>\n",
       "      <td>0.508472</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>288.102417</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>88</td>\n",
       "      <td>0.886176</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463627</th>\n",
       "      <td>3059777</td>\n",
       "      <td>206208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.542463</td>\n",
       "      <td>0.544971</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>176.729568</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>677</td>\n",
       "      <td>0.553786</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463628</th>\n",
       "      <td>2239861</td>\n",
       "      <td>206208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.528861</td>\n",
       "      <td>0.534091</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>176.729568</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>677</td>\n",
       "      <td>0.325015</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463629</th>\n",
       "      <td>1285346</td>\n",
       "      <td>206208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.520542</td>\n",
       "      <td>0.527629</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>176.729568</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>677</td>\n",
       "      <td>0.373723</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463630</th>\n",
       "      <td>1882108</td>\n",
       "      <td>206208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.530163</td>\n",
       "      <td>0.523381</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>176.729568</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>677</td>\n",
       "      <td>0.355284</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463631</th>\n",
       "      <td>803273</td>\n",
       "      <td>206208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>176.729568</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>677</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1463632 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_id  user_id  contains_alcohol  item_count  \\\n",
       "0         1374495        3               0.0        10.0   \n",
       "1          444309        3               0.0         9.0   \n",
       "2         3002854        3               0.0         6.0   \n",
       "3         2037211        3               0.0         5.0   \n",
       "4         2710558        3               0.0        11.0   \n",
       "...           ...      ...               ...         ...   \n",
       "1463627   3059777   206208               0.0         7.0   \n",
       "1463628   2239861   206208               0.0        23.0   \n",
       "1463629   1285346   206208               0.0         8.0   \n",
       "1463630   1882108   206208               0.0        17.0   \n",
       "1463631    803273   206208               0.0         NaN   \n",
       "\n",
       "         unique_departments_count  unique_aisles_count  \\\n",
       "0                             3.0                  4.0   \n",
       "1                             5.0                  9.0   \n",
       "2                             4.0                  6.0   \n",
       "3                             4.0                  5.0   \n",
       "4                             4.0                  7.0   \n",
       "...                           ...                  ...   \n",
       "1463627                       4.0                  6.0   \n",
       "1463628                       6.0                 14.0   \n",
       "1463629                       4.0                  6.0   \n",
       "1463630                       6.0                 12.0   \n",
       "1463631                       NaN                  NaN   \n",
       "\n",
       "         unique_departments_ratio  unique_aisles_ratio  \\\n",
       "0                        0.300000             0.400000   \n",
       "1                        0.555556             1.000000   \n",
       "2                        0.666667             1.000000   \n",
       "3                        0.800000             1.000000   \n",
       "4                        0.363636             0.636364   \n",
       "...                           ...                  ...   \n",
       "1463627                  0.571429             0.857143   \n",
       "1463628                  0.260870             0.608696   \n",
       "1463629                  0.500000             0.750000   \n",
       "1463630                  0.352941             0.705882   \n",
       "1463631                       NaN                  NaN   \n",
       "\n",
       "         avg_tip_rate_department  avg_tip_rate_aisle  ...  most_frequent_hour  \\\n",
       "0                       0.516237            0.523879  ...                  16   \n",
       "1                       0.502990            0.499790  ...                  16   \n",
       "2                       0.510314            0.507816  ...                  16   \n",
       "3                       0.442459            0.457083  ...                  16   \n",
       "4                       0.518061            0.508472  ...                  16   \n",
       "...                          ...                 ...  ...                 ...   \n",
       "1463627                 0.542463            0.544971  ...                  15   \n",
       "1463628                 0.528861            0.534091  ...                  15   \n",
       "1463629                 0.520542            0.527629  ...                  15   \n",
       "1463630                 0.530163            0.523381  ...                  15   \n",
       "1463631                      NaN                 NaN  ...                  15   \n",
       "\n",
       "         most_frequent_dow  avg_time_between_orders_hours  purchase_hour_sin  \\\n",
       "0                        5                     288.102417          -0.866025   \n",
       "1                        5                     288.102417          -0.866025   \n",
       "2                        5                     288.102417          -0.866025   \n",
       "3                        5                     288.102417          -0.866025   \n",
       "4                        5                     288.102417          -0.866025   \n",
       "...                    ...                            ...                ...   \n",
       "1463627                  0                     176.729568          -0.707107   \n",
       "1463628                  0                     176.729568          -0.707107   \n",
       "1463629                  0                     176.729568          -0.707107   \n",
       "1463630                  0                     176.729568          -0.707107   \n",
       "1463631                  0                     176.729568          -0.707107   \n",
       "\n",
       "         purchase_hour_cos  purchase_season_sin  purchase_season_cos  \\\n",
       "0                -0.500000         1.224647e-16            -1.000000   \n",
       "1                -0.500000         1.224647e-16            -1.000000   \n",
       "2                -0.500000         1.224647e-16            -1.000000   \n",
       "3                -0.500000         1.224647e-16            -1.000000   \n",
       "4                -0.500000         1.224647e-16            -1.000000   \n",
       "...                    ...                  ...                  ...   \n",
       "1463627          -0.707107         5.000000e-01             0.866025   \n",
       "1463628          -0.707107         5.000000e-01             0.866025   \n",
       "1463629          -0.707107         5.000000e-01             0.866025   \n",
       "1463630          -0.707107         5.000000e-01             0.866025   \n",
       "1463631          -0.707107         5.000000e-01             0.866025   \n",
       "\n",
       "         total_times_bought  tip_probability    tip  \n",
       "0                        88         0.849794   True  \n",
       "1                        88         0.714135   True  \n",
       "2                        88         0.791323   True  \n",
       "3                        88         0.900000   True  \n",
       "4                        88         0.886176   True  \n",
       "...                     ...              ...    ...  \n",
       "1463627                 677         0.553786  False  \n",
       "1463628                 677         0.325015   True  \n",
       "1463629                 677         0.373723   True  \n",
       "1463630                 677         0.355284   True  \n",
       "1463631                 677         0.500000    NaN  \n",
       "\n",
       "[1463632 rows x 32 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# In execution_count 2 (Helper Functions), aktualisiere downcast_dtypes\n",
    "def downcast_dtypes(df, exclude_columns=['order_id']):\n",
    "    \"\"\"Downcast numeric columns to reduce memory usage, excluding specified columns.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame to downcast.\n",
    "        exclude_columns (list): Columns to exclude from downcasting.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Downcasted DataFrame.\n",
    "    \"\"\"\n",
    "    for col in df.select_dtypes(include=['int64']).columns:\n",
    "        if col not in exclude_columns:\n",
    "            df[col] = pd.to_numeric(df[col], downcast='integer')\n",
    "    for col in df.select_dtypes(include=['float64']).columns:\n",
    "        df[col] = pd.to_numeric(df[col], downcast='float')\n",
    "    return df\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "def combine_all_features(default_tip_rate=0.5):\n",
    "    \"\"\"Combine all engineered features into a single DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        default_tip_rate (float): Standard-Trinkgeldwahrscheinlichkeit fÃ¼r fehlende Werte.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with all features, keyed by order_id, user_id, and including the tip column.\n",
    "    \"\"\"\n",
    "    # Base DataFrame with order_id and user_id\n",
    "    base_df = orders[['order_id', 'user_id']].copy()\n",
    "    base_df['order_id'] = base_df['order_id'].astype('int64')\n",
    "    base_df = downcast_dtypes(base_df, exclude_columns=['order_id'])\n",
    "    \n",
    "    # Merge order-level features\n",
    "    order_features = [\n",
    "        add_feature_order_contains_alcohol(),\n",
    "        add_feature_order_item_count(),\n",
    "        add_feature_order_unique_departments_count(),\n",
    "        add_feature_order_unique_aisles_count(),\n",
    "        add_feature_order_unique_departments_ratio(),\n",
    "        add_feature_order_unique_aisles_ratio(),\n",
    "        add_feature_avg_tip_rate_department(),\n",
    "        add_feature_avg_tip_rate_aisle(),\n",
    "        order_hour(),\n",
    "        order_dow(),\n",
    "        is_weekend_order(),\n",
    "        order_hour_cyclic(),\n",
    "        order_season_cyclic(),\n",
    "        time_since_last_order()\n",
    "    ]\n",
    "    \n",
    "    result = base_df\n",
    "    for feature_df in order_features:\n",
    "        if 'order_id' in feature_df.columns:\n",
    "            feature_df['order_id'] = feature_df['order_id'].astype('int64')\n",
    "            print(f\"Merging feature with columns {feature_df.columns.tolist()}, order_id dtype: {feature_df['order_id'].dtype}\")\n",
    "        else:\n",
    "            raise ValueError(f\"feature_df missing order_id: {feature_df.columns.tolist()}\")\n",
    "        \n",
    "        merge_cols = ['order_id']\n",
    "        feature_cols = [col for col in feature_df.columns if col not in merge_cols]\n",
    "        result_cols = [col for col in result.columns if col in feature_cols]\n",
    "        if result_cols:\n",
    "            result = result.drop(columns=result_cols)\n",
    "        result = result.merge(feature_df, on='order_id', how='left')\n",
    "        result = downcast_dtypes(result, exclude_columns=['order_id'])\n",
    "    \n",
    "    # Merge user-level features\n",
    "    user_features = [\n",
    "        add_feature_alcohol_count(),\n",
    "        total_products_per_user(),\n",
    "        total_unique_products_per_user(),\n",
    "        unique_to_total_product_ratio_per_user(),\n",
    "        most_frequent_purchase_hour(),\n",
    "        most_frequent_purchase_dow(),\n",
    "        avg_time_between_orders(),\n",
    "        purchase_hour_cyclic(),\n",
    "        purchase_season_cyclic()\n",
    "    ]\n",
    "    \n",
    "    for feature_df in user_features:\n",
    "        merge_cols = ['user_id']\n",
    "        feature_cols = [col for col in feature_df.columns if col not in merge_cols]\n",
    "        result_cols = [col for col in result.columns if col in feature_cols]\n",
    "        if result_cols:\n",
    "            result = result.drop(columns=result_cols)\n",
    "        result = result.merge(feature_df, on='user_id', how='left')\n",
    "        result = downcast_dtypes(result, exclude_columns=['order_id'])\n",
    "    \n",
    "    # Aggregate user-product-level features to user level\n",
    "    user_product = count_products_per_user()\n",
    "    user_product_sum = user_product.groupby('user_id')['times_bought'].sum().reset_index(name='total_times_bought')\n",
    "    user_product_agg = orders[['order_id', 'user_id']].merge(user_product_sum, on='user_id', how='left')\n",
    "    user_product_agg['order_id'] = user_product_agg['order_id'].astype('int64')\n",
    "    user_product_agg['total_times_bought'] = user_product_agg['total_times_bought'].fillna(0)\n",
    "    user_product_agg = downcast_dtypes(user_product_agg, exclude_columns=['order_id'])\n",
    "    result = result.merge(user_product_agg[['order_id', 'user_id', 'total_times_bought']], on=['order_id', 'user_id'], how='left')\n",
    "    \n",
    "    # Add user-product tip probability\n",
    "    user_product_tip_df = create_user_product_tip_probability(default_tip_rate=default_tip_rate)\n",
    "    user_product_tip_df['order_id'] = user_product_tip_df['order_id'].astype('int64')\n",
    "    # Aggregiere tip_probability auf order_id-Ebene (Mittelwert)\n",
    "    tip_prob_agg = user_product_tip_df.groupby('order_id')['tip_probability'].mean().reset_index()\n",
    "    result = result.merge(\n",
    "        tip_prob_agg[['order_id', 'tip_probability']],\n",
    "        on='order_id',\n",
    "        how='left'\n",
    "    )\n",
    "    result['tip_probability'] = result['tip_probability'].fillna(default_tip_rate).astype('float32')\n",
    "    result = downcast_dtypes(result, exclude_columns=['order_id'])\n",
    "    \n",
    "    # Add target variable (tip)\n",
    "    result = result.merge(tips_public[['order_id', 'tip']], on='order_id', how='left')\n",
    "    result = downcast_dtypes(result, exclude_columns=['order_id'])\n",
    "    \n",
    "    # Validate\n",
    "    expected_columns = [\n",
    "        'order_id', 'user_id', 'contains_alcohol', 'item_count', 'unique_departments_count',\n",
    "        'unique_aisles_count', 'unique_departments_ratio', 'unique_aisles_ratio',\n",
    "        'avg_tip_rate_department', 'avg_tip_rate_aisle', 'order_hour', 'order_dow',\n",
    "        'is_weekend', 'order_hour_sin', 'order_hour_cos', 'order_season_sin',\n",
    "        'order_season_cos', 'time_since_last_order_hours',\n",
    "        'alcohol_purchases', 'total_products_bought', 'unique_products_bought',\n",
    "        'unique_to_total_product_ratio', 'most_frequent_hour', 'most_frequent_dow',\n",
    "        'avg_time_between_orders_hours', 'purchase_hour_sin', 'purchase_hour_cos',\n",
    "        'purchase_season_sin', 'purchase_season_cos', 'total_times_bought',\n",
    "        'tip_probability', 'tip'\n",
    "    ]\n",
    "    validate_dataframe(result, expected_columns)\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Generate and display the combined feature DataFrame\n",
    "all_features_df = combine_all_features()\n",
    "display(all_features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "testing",
   "metadata": {},
   "source": [
    "## Feature Validation\n",
    "\n",
    "Basic tests to ensure feature correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_feature_tests():\n",
    "    \"\"\"Run basic validation tests on features.\"\"\"\n",
    "    # Test alcohol count\n",
    "    alcohol_count = add_feature_alcohol_count()\n",
    "    assert alcohol_count['alcohol_purchases'].ge(0).all(), \"Alcohol purchases cannot be negative\"\n",
    "    \n",
    "    # Test unique to total product ratio\n",
    "    ratio = unique_to_total_product_ratio_per_user()\n",
    "    assert ratio['unique_to_total_product_ratio'].between(0, 1).all(), \"Ratio must be between 0 and 1\"\n",
    "    \n",
    "    # Test order item count\n",
    "    item_count = add_feature_order_item_count()\n",
    "    assert item_count['item_count'].ge(1).all(), \"Item count must be at least 1\"\n",
    "    \n",
    "    # Test department tip rate\n",
    "    dept_tip_rate = add_feature_avg_tip_rate_department()\n",
    "    assert dept_tip_rate['avg_tip_rate_department'].between(0, 1).all(), \"Department tip rate must be between 0 and 1\"\n",
    "    \n",
    "    # Test aisle tip rate\n",
    "    aisle_tip_rate = add_feature_avg_tip_rate_aisle()\n",
    "    assert aisle_tip_rate['avg_tip_rate_aisle'].between(0, 1).all(), \"Aisle tip rate must be between 0 and 1\"\n",
    "    \n",
    "    # Test most frequent hour\n",
    "    freq_hour = most_frequent_purchase_hour()\n",
    "    assert freq_hour['most_frequent_hour'].between(0, 23).all(), \"Hour must be between 0 and 23\"\n",
    "    \n",
    "    # Test cyclic transformations\n",
    "    hour_cyclic = purchase_hour_cyclic()\n",
    "    assert ((hour_cyclic['purchase_hour_sin'] >= -1) & (hour_cyclic['purchase_hour_sin'] <= 1) &\n",
    "            (hour_cyclic['purchase_hour_cos'] >= -1) & (hour_cyclic['purchase_hour_cos'] <= 1)).all(), \\\n",
    "            \"Cyclic values must be between -1 and 1\"\n",
    "    \n",
    "    # Test time since last order\n",
    "    time_since = time_since_last_order()\n",
    "    assert time_since['time_since_last_order_hours'].ge(0).all(), \"Time since last order cannot be negative\"\n",
    "    \n",
    "    # Test user-product tip probability\n",
    "    user_product_tip_df = create_user_product_tip_probability()\n",
    "    assert user_product_tip_df['tip_probability'].between(0, 1).all(), \"Tip probability must be between 0 and 1\"\n",
    "    assert len(user_product_tip_df) == len(order_products_denormalized), \"Row count must match order_products_denormalized\"\n",
    "    \n",
    "    # Test combined features\n",
    "    combined_df = combine_all_features()\n",
    "    assert combined_df['order_id'].nunique() == orders['order_id'].nunique(), \"Combined DataFrame must contain all orders\"\n",
    "    assert combined_df['tip'].notna().sum() == tips_public['tip'].notna().sum(), \"Combined DataFrame must preserve all tip values\"\n",
    "    \n",
    "    print(\"All tests passed!\")\n",
    "\n",
    "#run_feature_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
